{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ea7eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd() \n",
    "os.chdir(os.pardir)\n",
    "os.getcwd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683da4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.comet_models import LatentEBM, LatentEBM128\n",
    "from src.config.load_config import load_config\n",
    "from src.dataloader import MRI2D\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from src.test_final import gen_image as gen_image_our"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea85c1e0",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9efb2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_last_recon(checkpoint_path, model_type):\n",
    "    config_path = '/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/config/2DMRI_config.yml'\n",
    "    dataset_type = 'MRI2D'\n",
    "\n",
    "    run_name = checkpoint_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    logging.info(f\"Run name: {run_name}\")\n",
    "    # Load configuration\n",
    "    config = load_config(config_path)\n",
    "    logging.info(f\"Loaded config: {config}\")\n",
    "\n",
    "    run_name = checkpoint_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    logging.info(f\"Run name: {run_name}\")\n",
    "\n",
    "    dataset = MRI2D(config)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load model\n",
    "    if model_type == \"LatentEBM\":\n",
    "        model_class = LatentEBM\n",
    "    elif model_type == \"LatentEBM128\":\n",
    "        model_class = LatentEBM128\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    state_dicts = checkpoint if isinstance(checkpoint, list) else [checkpoint]\n",
    "    models = [model_class(config, dataset_type).to(device) for _ in range(len(state_dicts))]\n",
    "    for i, model in enumerate(models):\n",
    "        model.load_state_dict(state_dicts[i], strict=False)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "\n",
    "\n",
    "    # Prepare data\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=config.data_workers)\n",
    "    im, _ = next(iter(dataloader))\n",
    "    im = im.to(device)\n",
    "\n",
    "    # Embed latent\n",
    "    latent = models[0].embed_latent(im)\n",
    "    latents = torch.chunk(latent, config.components, dim=1)\n",
    "    # each latent is a component, and has size (batch_size, latent_dim)\n",
    "\n",
    "    im_neg = torch.rand_like(im)\n",
    "    im_negs = gen_image_our(latents, config, models, im_neg, 30)\n",
    "\n",
    "    our_final_image = im_negs[-1][0].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "    print(our_final_image.shape)\n",
    "\n",
    "    return our_final_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69fe11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/.venv/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LatentEBM128:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([8, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 1, 3, 3]).\n\tsize mismatch for conv1.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for gain.weight: copying a param with shape torch.Size([8, 64]) from checkpoint, the shape in current model is torch.Size([4, 64]).\n\tsize mismatch for gain.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for bias.weight: copying a param with shape torch.Size([8, 64]) from checkpoint, the shape in current model is torch.Size([4, 64]).\n\tsize mismatch for bias.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for layer_encode.conv1.weight: copying a param with shape torch.Size([8, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 4, 3, 3]).\n\tsize mismatch for layer_encode.conv1.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for layer_encode.conv2.weight: copying a param with shape torch.Size([8, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 4, 3, 3]).\n\tsize mismatch for layer_encode.conv2.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for layer_encode.latent_fc1.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([8, 64]).\n\tsize mismatch for layer_encode.latent_fc1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer_encode.latent_fc2.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([8, 64]).\n\tsize mismatch for layer_encode.latent_fc2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer_encode.conv_downsample.weight: copying a param with shape torch.Size([16, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 4, 3, 3]).\n\tsize mismatch for layer_encode.conv_downsample.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer1.conv1.weight: copying a param with shape torch.Size([16, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 8, 3, 3]).\n\tsize mismatch for layer1.conv1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer1.conv2.weight: copying a param with shape torch.Size([16, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 8, 3, 3]).\n\tsize mismatch for layer1.conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer1.latent_fc1.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([16, 64]).\n\tsize mismatch for layer1.latent_fc1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer1.latent_fc2.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([16, 64]).\n\tsize mismatch for layer1.latent_fc2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer1.conv_downsample.weight: copying a param with shape torch.Size([32, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 8, 3, 3]).\n\tsize mismatch for layer1.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer2.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer2.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer2.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer2.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer2.latent_fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer2.latent_fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer2.latent_fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer2.latent_fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer2.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer2.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer3.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer3.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer3.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer3.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer3.latent_fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer3.latent_fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer3.latent_fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer3.latent_fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer3.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer3.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer4.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer4.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer4.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer4.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer4.latent_fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer4.latent_fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer4.latent_fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer4.latent_fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer4.conv_downsample.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n\tsize mismatch for layer4.conv_downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for latent_map.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for latent_map.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for energy_map.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for embed_conv1.weight: copying a param with shape torch.Size([32, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 1, 3, 3]).\n\tsize mismatch for embed_conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer1.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer2.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer2.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer2.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer3.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer3.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer3.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer1.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer2.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer2.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer2.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer3.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer3.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer3.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for latent_decode.weight: copying a param with shape torch.Size([256, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 16, 3, 3]).\n\tsize mismatch for latent_decode.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for embed_fc1.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for embed_fc1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_fc2.weight: copying a param with shape torch.Size([256, 32]) from checkpoint, the shape in current model is torch.Size([576, 16]).\n\tsize mismatch for embed_fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([576]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m checkpoint_ebm128 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/models/latentEBM128_UN_767.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m latentebm128_image \u001b[38;5;241m=\u001b[39m \u001b[43mget_last_recon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_ebm128\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLatentEBM128\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m checkpoint_ebm \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/models/latentEBM_old_UN768.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m latentebm_image \u001b[38;5;241m=\u001b[39m get_last_recon(checkpoint_ebm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatentEBM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m, in \u001b[0;36mget_last_recon\u001b[0;34m(checkpoint_path, model_type)\u001b[0m\n\u001b[1;32m     28\u001b[0m models \u001b[38;5;241m=\u001b[39m [model_class(config, dataset_type)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(state_dicts))]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dicts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set to evaluation mode\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Prepare data\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/UNI/6sem/bach/energy-based-representation-learning/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LatentEBM128:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([8, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 1, 3, 3]).\n\tsize mismatch for conv1.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for gain.weight: copying a param with shape torch.Size([8, 64]) from checkpoint, the shape in current model is torch.Size([4, 64]).\n\tsize mismatch for gain.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for bias.weight: copying a param with shape torch.Size([8, 64]) from checkpoint, the shape in current model is torch.Size([4, 64]).\n\tsize mismatch for bias.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for layer_encode.conv1.weight: copying a param with shape torch.Size([8, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 4, 3, 3]).\n\tsize mismatch for layer_encode.conv1.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for layer_encode.conv2.weight: copying a param with shape torch.Size([8, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 4, 3, 3]).\n\tsize mismatch for layer_encode.conv2.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([4]).\n\tsize mismatch for layer_encode.latent_fc1.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([8, 64]).\n\tsize mismatch for layer_encode.latent_fc1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer_encode.latent_fc2.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([8, 64]).\n\tsize mismatch for layer_encode.latent_fc2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer_encode.conv_downsample.weight: copying a param with shape torch.Size([16, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 4, 3, 3]).\n\tsize mismatch for layer_encode.conv_downsample.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer1.conv1.weight: copying a param with shape torch.Size([16, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 8, 3, 3]).\n\tsize mismatch for layer1.conv1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer1.conv2.weight: copying a param with shape torch.Size([16, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 8, 3, 3]).\n\tsize mismatch for layer1.conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for layer1.latent_fc1.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([16, 64]).\n\tsize mismatch for layer1.latent_fc1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer1.latent_fc2.weight: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([16, 64]).\n\tsize mismatch for layer1.latent_fc2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer1.conv_downsample.weight: copying a param with shape torch.Size([32, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 8, 3, 3]).\n\tsize mismatch for layer1.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer2.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer2.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer2.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer2.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer2.latent_fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer2.latent_fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer2.latent_fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer2.latent_fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer2.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer2.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer3.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer3.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer3.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer3.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer3.latent_fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer3.latent_fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer3.latent_fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer3.latent_fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer3.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer3.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer4.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer4.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer4.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for layer4.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for layer4.latent_fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer4.latent_fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer4.latent_fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for layer4.latent_fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for layer4.conv_downsample.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n\tsize mismatch for layer4.conv_downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for latent_map.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for latent_map.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for energy_map.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for embed_conv1.weight: copying a param with shape torch.Size([32, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 1, 3, 3]).\n\tsize mismatch for embed_conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer1.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer1.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer2.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer2.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer2.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer2.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer3.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer3.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_layer3.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for embed_layer3.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer1.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer1.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer2.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer2.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer2.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer2.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.conv1.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer3.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.conv2.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer3.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.bn2.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.bn2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decode_layer3.conv_downsample.weight: copying a param with shape torch.Size([32, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 16, 3, 3]).\n\tsize mismatch for decode_layer3.conv_downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for latent_decode.weight: copying a param with shape torch.Size([256, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([576, 16, 3, 3]).\n\tsize mismatch for latent_decode.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([576]).\n\tsize mismatch for embed_fc1.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for embed_fc1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for embed_fc2.weight: copying a param with shape torch.Size([256, 32]) from checkpoint, the shape in current model is torch.Size([576, 16]).\n\tsize mismatch for embed_fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([576])."
     ]
    }
   ],
   "source": [
    "checkpoint_ebm128 = '/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/models/latentEBM128_UN_767.pth'\n",
    "latentebm128_image = get_last_recon(checkpoint_ebm128, 'LatentEBM128')\n",
    "\n",
    "checkpoint_ebm = '/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/models/latentEBM_old_UN768.pth'\n",
    "latentebm_image = get_last_recon(checkpoint_ebm, 'LatentEBM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3571ec",
   "metadata": {},
   "source": [
    "# LatentEBM128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_ebm128 = '/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/models/latentEBM128_UN_767.pth'\n",
    "\n",
    "config_path = '/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/config/2DMRI_config.yml'\n",
    "dataset_type = 'MRI2D'\n",
    "\n",
    "run_name = checkpoint_ebm128.split(\"/\")[-1].split(\".\")[0]\n",
    "logging.info(f\"Run name: {run_name}\")\n",
    "# Load configuration\n",
    "config = load_config(config_path)\n",
    "logging.info(f\"Loaded config: {config}\")\n",
    "\n",
    "run_name = checkpoint_ebm128.split(\"/\")[-1].split(\".\")[0]\n",
    "logging.info(f\"Run name: {run_name}\")\n",
    "\n",
    "dataset = MRI2D(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_ebm128, map_location=device)\n",
    "state_dicts = checkpoint if isinstance(checkpoint, list) else [checkpoint]\n",
    "models = [LatentEBM128(config, dataset_type).to(device) for _ in range(len(state_dicts))]\n",
    "for i, model in enumerate(models):\n",
    "    model.load_state_dict(state_dicts[i], strict=False)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=config.data_workers)\n",
    "im, _ = next(iter(dataloader))\n",
    "im = im.to(device)\n",
    "\n",
    "# Embed latent\n",
    "latent = models[0].embed_latent(im)\n",
    "latents = torch.chunk(latent, config.components, dim=1)\n",
    "# each latent is a component, and has size (batch_size, latent_dim)\n",
    "\n",
    "im_neg = torch.rand_like(im)\n",
    "im_negs = gen_image_our(latents, config, models, im_neg, 30)\n",
    "\n",
    "our_final_image = im_negs[-1][0].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "print(our_final_image.shape)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

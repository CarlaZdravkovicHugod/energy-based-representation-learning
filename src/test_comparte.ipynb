{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from dataloader import MRI2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efb2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_ebm128 = '/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/models/latentEBM128_UN_767.pth'\n",
    "latentebm128_image = get_last_recon(checkpoint_ebm128, 'LatentEBM128')\n",
    "\n",
    "checkpoint_ebm = '/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/models/latentEBM_old_UN768.pth'\n",
    "latentebm_image = get_last_recon(checkpoint_ebm, 'LatentEBM')\n",
    "\n",
    "\n",
    "def get_last_recon(checkpoint_path, model_type):\n",
    "    config_path = '/Users/carlahugod/Desktop/UNI/6sem/bach/energy-based-representation-learning/src/config/2DMRI_config.yml'\n",
    "    dataset_type = 'MRI2D'\n",
    "\n",
    "    run_name = checkpoint_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    logging.info(f\"Run name: {run_name}\")\n",
    "    # Load configuration\n",
    "    config = load_config(config_path)\n",
    "    logging.info(f\"Loaded config: {config}\")\n",
    "\n",
    "    run_name = checkpoint_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    logging.info(f\"Run name: {run_name}\")\n",
    "\n",
    "    dataset = MRI2D(config)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load model\n",
    "    if model_type == \"LatentEBM\":\n",
    "        model_class = LatentEBM\n",
    "    elif model_type == \"LatentEBM128\":\n",
    "        model_class = LatentEBM128\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    state_dicts = checkpoint if isinstance(checkpoint, list) else [checkpoint]\n",
    "    models = [model_class(config, dataset_type).to(device) for _ in range(len(state_dicts))]\n",
    "    for i, model in enumerate(models):\n",
    "        model.load_state_dict(state_dicts[i], strict=False)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "\n",
    "\n",
    "    # Prepare data\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=config.data_workers)\n",
    "    im, _ = next(iter(dataloader))\n",
    "    im = im.to(device)\n",
    "\n",
    "    # Embed latent\n",
    "    latent = models[0].embed_latent(im)\n",
    "    latents = torch.chunk(latent, config.components, dim=1)\n",
    "    # each latent is a component, and has size (batch_size, latent_dim)\n",
    "\n",
    "    im_neg = torch.rand_like(im)\n",
    "    im_negs = gen_image_our(latents, config, models, im_neg, 30)\n",
    "\n",
    "    our_final_image = im_negs[-1][0].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "    print(our_final_image.shape)\n",
    "\n",
    "    return our_final_image\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
